## Prototype LLM applications and deploy, monitor, and improve them in production!
In just 7-weeks, this adventure will take you on a journey with the AI Makerspace community from prototyping to production to Demo Day!

You will learn to prototype LLM applications first through prompt engineering, then layering in Retrieval Augmented Generation (RAG) and fine-tuning of both LLMs and embedding models. You will get many iterations of hands-on practice of deploying LLM web applications to a public URL with a slick user interface!

You will learn how to move from prototyping into production by applying RAG evaluation and improvement techniques, outfitting your applications with monitoring and visibility tooling, leveraging efficient inference and serving techniques, and deploying scalable endpoints.

## Who is this course for

### What youâ€™ll get out of this course
- ğŸ§‘â€ğŸ’» Prompt Engineering: Leverage in-context learning as an engineer for prototyping, RAG applications, agents, and more!
- ğŸ™‹ RAG: Build Retrieval Augmented Generation applications and ground LLM outputs in your own reference data
- âš–ï¸ Fine-Tuning: Efficiently train LLMs to perform specific tasks using techniques like LoRA and quantization
- ğŸ•´ï¸ Agents: Build complex LLM applications capable of reasoning, action, and working with external tools
- ğŸ“ˆ Evaluation: How to instrument LLM applications for quantitative metrics-driven development
- ğŸ” Visibility: Debug, test, and monitor applications built using any leading LLM framework
- ğŸš€ Serving: Ensure efficient and scalable inference using the right tools and techniques
